The original data shows a somewhat weak correlation between the amount of hours played, age, and the subscription status of player. From our model, it was predicted that a majority of players are subscribed to the newsletter. The trends in our predicted data, though, show that there is a weak correlation between player age, hours played, and subscription status. To analyze the performance of our classifier model, we performed accuracy, recall and precision tests. We found that the accuracy of our model was only 57%, meaning that the model only predicted the correct class of the player 57 percent of the time, which is quite a low accuracy. Our recall and precision tests were both 71%, meaning that when our model labelled a player as subscribed, it was right 71% of the time. The recall and precision are higher than the accuracy, but from our side-by-side scatter plots of the original data and our model data, we can see our model was good at predicting if a player was subscribed to the newsletter, but difficulty if the player was not subscribed to the game.
To improve our model and avoid the issues of low accuracy, average recall, and precision, we can start by weighting each class equally within our data. Since more players within the data were subscribed compared to players that were not, this could be the potential reason that the model had issues predicting players that were not subscribed to the newsletter. Adjusting the weights of the classes within our model could help solve this issue and lead to a more accurate model prediction. These adjustments should be made before using our model to help predict player subscription status in the real world.
Additionally, from the results of our model, we can ask questions for potential future models, such as using more predictors within the players.csv dataset to predict subscription status along with age and hours played.
